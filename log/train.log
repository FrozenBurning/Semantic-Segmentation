_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, None, None, 3)     0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, None, None, 64)    1792      
_________________________________________________________________
block1_conv2 (Conv2D)        (None, None, None, 64)    36928     
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, None, None, 64)    0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, None, None, 128)   73856     
_________________________________________________________________
block2_conv2 (Conv2D)        (None, None, None, 128)   147584    
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, None, None, 128)   0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, None, None, 256)   295168    
_________________________________________________________________
block3_conv2 (Conv2D)        (None, None, None, 256)   590080    
_________________________________________________________________
block3_conv3 (Conv2D)        (None, None, None, 256)   590080    
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, None, None, 256)   0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   
_________________________________________________________________
block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   
_________________________________________________________________
block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, None, None, 512)   0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   
_________________________________________________________________
block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   
_________________________________________________________________
block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, None, None, 512)   0         
_________________________________________________________________
fc1 (Conv2D)                 (None, None, None, 4096)  102764544 
_________________________________________________________________
dropout_1 (Dropout)          (None, None, None, 4096)  0         
_________________________________________________________________
fc2 (Conv2D)                 (None, None, None, 4096)  16781312  
_________________________________________________________________
dropout_2 (Dropout)          (None, None, None, 4096)  0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, None, None, 12)    49164     
_________________________________________________________________
bilinear_up_sampling2d_1 (Bi (None, None, None, 12)    0         
=================================================================
Total params: 134,309,708
Trainable params: 134,309,708
Non-trainable params: 0
_________________________________________________________________
(311, 224, 224, 3) (311, 224, 224, 12)
(56, 224, 224, 3) (56, 224, 224, 12)
Train on 311 samples, validate on 56 samples
Epoch 1/300
16s - loss: 3.0133 - acc: 0.3637 - val_loss: 2.4424 - val_acc: 0.5331
Epoch 2/300
7s - loss: 2.3192 - acc: 0.5234 - val_loss: 2.3451 - val_acc: 0.5396
Epoch 3/300
8s - loss: 2.2487 - acc: 0.5293 - val_loss: 2.2445 - val_acc: 0.5427
Epoch 4/300
7s - loss: 2.2129 - acc: 0.5571 - val_loss: 2.2461 - val_acc: 0.6146
Epoch 5/300
7s - loss: 2.1833 - acc: 0.5972 - val_loss: 2.2256 - val_acc: 0.6239
Epoch 6/300
7s - loss: 2.1717 - acc: 0.6052 - val_loss: 2.2016 - val_acc: 0.6285
Epoch 7/300
7s - loss: 2.1500 - acc: 0.6118 - val_loss: 2.1860 - val_acc: 0.6322
Epoch 8/300
7s - loss: 2.1323 - acc: 0.6205 - val_loss: 2.1901 - val_acc: 0.6327
Epoch 9/300
7s - loss: 2.1148 - acc: 0.6244 - val_loss: 2.1351 - val_acc: 0.6465
Epoch 10/300
7s - loss: 2.0826 - acc: 0.6349 - val_loss: 2.1280 - val_acc: 0.6521
Epoch 11/300
8s - loss: 2.0983 - acc: 0.6381 - val_loss: 2.1646 - val_acc: 0.6494
Epoch 12/300
7s - loss: 2.1021 - acc: 0.6377 - val_loss: 2.1098 - val_acc: 0.6534
Epoch 13/300
7s - loss: 2.0748 - acc: 0.6395 - val_loss: 2.1079 - val_acc: 0.6525
Epoch 14/300
7s - loss: 2.0491 - acc: 0.6473 - val_loss: 2.0924 - val_acc: 0.6568
Epoch 15/300
8s - loss: 2.0429 - acc: 0.6500 - val_loss: 2.1010 - val_acc: 0.6618
Epoch 16/300
7s - loss: 2.0333 - acc: 0.6549 - val_loss: 2.0736 - val_acc: 0.6637
Epoch 17/300
7s - loss: 2.0508 - acc: 0.6531 - val_loss: 2.1428 - val_acc: 0.6596
Epoch 18/300
7s - loss: 2.0334 - acc: 0.6584 - val_loss: 2.0638 - val_acc: 0.6673
Epoch 19/300
7s - loss: 2.0105 - acc: 0.6594 - val_loss: 2.0581 - val_acc: 0.6707
Epoch 20/300
7s - loss: 2.0152 - acc: 0.6603 - val_loss: 2.0628 - val_acc: 0.6709
Epoch 21/300
7s - loss: 2.0136 - acc: 0.6628 - val_loss: 2.0569 - val_acc: 0.6718
Epoch 22/300
8s - loss: 1.9999 - acc: 0.6667 - val_loss: 2.0512 - val_acc: 0.6741
Epoch 23/300
7s - loss: 1.9936 - acc: 0.6676 - val_loss: 2.0549 - val_acc: 0.6752
Epoch 24/300
8s - loss: 1.9901 - acc: 0.6705 - val_loss: 2.0414 - val_acc: 0.6793
Epoch 25/300
8s - loss: 1.9742 - acc: 0.6707 - val_loss: 2.0471 - val_acc: 0.6718
Epoch 26/300
7s - loss: 1.9729 - acc: 0.6702 - val_loss: 2.0229 - val_acc: 0.6799
Epoch 27/300
7s - loss: 1.9601 - acc: 0.6747 - val_loss: 2.0423 - val_acc: 0.6789
Epoch 28/300
7s - loss: 1.9686 - acc: 0.6758 - val_loss: 2.0258 - val_acc: 0.6817
Epoch 29/300
7s - loss: 1.9664 - acc: 0.6766 - val_loss: 2.0158 - val_acc: 0.6845
Epoch 30/300
7s - loss: 1.9519 - acc: 0.6790 - val_loss: 1.9974 - val_acc: 0.6868
Epoch 31/300
7s - loss: 1.9450 - acc: 0.6785 - val_loss: 1.9953 - val_acc: 0.6876
Epoch 32/300
8s - loss: 1.9467 - acc: 0.6777 - val_loss: 1.9965 - val_acc: 0.6872
Epoch 33/300
7s - loss: 1.9295 - acc: 0.6841 - val_loss: 1.9992 - val_acc: 0.6870
Epoch 34/300
7s - loss: 1.9307 - acc: 0.6838 - val_loss: 1.9770 - val_acc: 0.6945
Epoch 35/300
7s - loss: 1.9282 - acc: 0.6826 - val_loss: 1.9929 - val_acc: 0.6888
Epoch 36/300
7s - loss: 1.9211 - acc: 0.6844 - val_loss: 1.9772 - val_acc: 0.6943
Epoch 37/300
7s - loss: 1.9168 - acc: 0.6874 - val_loss: 1.9924 - val_acc: 0.6902
Epoch 38/300
8s - loss: 1.9262 - acc: 0.6836 - val_loss: 1.9909 - val_acc: 0.6920
Epoch 39/300
7s - loss: 1.9196 - acc: 0.6865 - val_loss: 1.9750 - val_acc: 0.6962
Epoch 40/300
7s - loss: 1.9064 - acc: 0.6926 - val_loss: 1.9604 - val_acc: 0.6999
Epoch 41/300
7s - loss: 1.8920 - acc: 0.6947 - val_loss: 1.9482 - val_acc: 0.7040
Epoch 42/300
8s - loss: 1.8830 - acc: 0.7045 - val_loss: 1.9543 - val_acc: 0.7117
Epoch 43/300
8s - loss: 1.8729 - acc: 0.7108 - val_loss: 1.9359 - val_acc: 0.7179
Epoch 44/300
7s - loss: 1.8574 - acc: 0.7161 - val_loss: 1.9217 - val_acc: 0.7234
Epoch 45/300
8s - loss: 1.8569 - acc: 0.7202 - val_loss: 1.9471 - val_acc: 0.7189
Epoch 46/300
7s - loss: 1.8461 - acc: 0.7225 - val_loss: 2.0659 - val_acc: 0.6758
Epoch 47/300
8s - loss: 1.9530 - acc: 0.6813 - val_loss: 2.0072 - val_acc: 0.6898
Epoch 48/300
7s - loss: 1.9305 - acc: 0.6885 - val_loss: 1.9646 - val_acc: 0.6968
Epoch 49/300
8s - loss: 1.8980 - acc: 0.6972 - val_loss: 2.0352 - val_acc: 0.6879
Epoch 50/300
8s - loss: 1.9382 - acc: 0.6919 - val_loss: 1.9759 - val_acc: 0.6994
Epoch 51/300
8s - loss: 1.8902 - acc: 0.7037 - val_loss: 1.9414 - val_acc: 0.7088
Epoch 52/300
8s - loss: 1.8665 - acc: 0.7135 - val_loss: 1.9272 - val_acc: 0.7202
Epoch 53/300
8s - loss: 1.8457 - acc: 0.7210 - val_loss: 1.9115 - val_acc: 0.7251
Epoch 54/300
7s - loss: 1.8423 - acc: 0.7238 - val_loss: 1.9167 - val_acc: 0.7248
Epoch 55/300
8s - loss: 1.8255 - acc: 0.7324 - val_loss: 1.9020 - val_acc: 0.7296
Epoch 56/300
8s - loss: 1.8047 - acc: 0.7375 - val_loss: 1.9138 - val_acc: 0.7331
Epoch 57/300
7s - loss: 1.8027 - acc: 0.7389 - val_loss: 1.8930 - val_acc: 0.7370
Epoch 58/300
7s - loss: 1.7931 - acc: 0.7424 - val_loss: 1.8866 - val_acc: 0.7407
Epoch 59/300
7s - loss: 1.7772 - acc: 0.7499 - val_loss: 1.8796 - val_acc: 0.7421
Epoch 60/300
7s - loss: 1.7691 - acc: 0.7530 - val_loss: 1.8756 - val_acc: 0.7476
Epoch 61/300
8s - loss: 1.7597 - acc: 0.7550 - val_loss: 1.8934 - val_acc: 0.7479
Epoch 62/300
8s - loss: 1.7750 - acc: 0.7538 - val_loss: 1.9054 - val_acc: 0.7475
Epoch 63/300
8s - loss: 1.7666 - acc: 0.7564 - val_loss: 1.9266 - val_acc: 0.7498
Epoch 64/300
7s - loss: 1.7688 - acc: 0.7558 - val_loss: 1.8611 - val_acc: 0.7532
Epoch 65/300
7s - loss: 1.7578 - acc: 0.7586 - val_loss: 1.8858 - val_acc: 0.7420
Epoch 66/300
7s - loss: 1.8831 - acc: 0.7003 - val_loss: 2.0990 - val_acc: 0.6131
Epoch 67/300
7s - loss: 2.0020 - acc: 0.6571 - val_loss: 2.0300 - val_acc: 0.6774
Epoch 68/300
7s - loss: 1.9585 - acc: 0.6771 - val_loss: 2.0151 - val_acc: 0.6916
Epoch 69/300
7s - loss: 1.9438 - acc: 0.6859 - val_loss: 2.0075 - val_acc: 0.6903
Epoch 70/300
8s - loss: 1.9115 - acc: 0.6935 - val_loss: 1.9967 - val_acc: 0.6955
Epoch 71/300
7s - loss: 1.8985 - acc: 0.6979 - val_loss: 1.9562 - val_acc: 0.7133
Epoch 72/300
7s - loss: 1.8694 - acc: 0.7156 - val_loss: 1.9323 - val_acc: 0.7192
Epoch 73/300
7s - loss: 1.8439 - acc: 0.7229 - val_loss: 1.8989 - val_acc: 0.7341
Epoch 74/300
8s - loss: 1.8091 - acc: 0.7349 - val_loss: 1.8981 - val_acc: 0.7401
Epoch 75/300
7s - loss: 1.7869 - acc: 0.7469 - val_loss: 1.8829 - val_acc: 0.7406
Epoch 76/300
7s - loss: 1.8100 - acc: 0.7379 - val_loss: 1.9221 - val_acc: 0.7364
Epoch 77/300
7s - loss: 1.8008 - acc: 0.7423 - val_loss: 1.8808 - val_acc: 0.7441
Epoch 78/300
7s - loss: 1.7878 - acc: 0.7497 - val_loss: 1.8832 - val_acc: 0.7467
Epoch 79/300
8s - loss: 1.7695 - acc: 0.7552 - val_loss: 1.8598 - val_acc: 0.7522
Epoch 80/300
7s - loss: 1.7595 - acc: 0.7568 - val_loss: 1.8577 - val_acc: 0.7502
Epoch 81/300
8s - loss: 1.8004 - acc: 0.7429 - val_loss: 1.9278 - val_acc: 0.7318
Epoch 82/300
8s - loss: 1.8139 - acc: 0.7386 - val_loss: 1.8908 - val_acc: 0.7442
Epoch 83/300
8s - loss: 1.8017 - acc: 0.7445 - val_loss: 1.9118 - val_acc: 0.7371
Epoch 84/300
7s - loss: 1.7685 - acc: 0.7539 - val_loss: 1.8626 - val_acc: 0.7515
Epoch 85/300
7s - loss: 1.7480 - acc: 0.7612 - val_loss: 1.8646 - val_acc: 0.7547
Epoch 86/300
7s - loss: 1.7705 - acc: 0.7521 - val_loss: 1.8779 - val_acc: 0.7456
Epoch 87/300
7s - loss: 1.7610 - acc: 0.7592 - val_loss: 1.8778 - val_acc: 0.7470
Epoch 88/300
7s - loss: 1.7668 - acc: 0.7603 - val_loss: 1.8954 - val_acc: 0.7479
Epoch 89/300
7s - loss: 1.7598 - acc: 0.7596 - val_loss: 1.8487 - val_acc: 0.7549
Epoch 90/300
7s - loss: 1.7493 - acc: 0.7607 - val_loss: 1.8603 - val_acc: 0.7570
Epoch 91/300
7s - loss: 1.7334 - acc: 0.7664 - val_loss: 1.8634 - val_acc: 0.7587
Epoch 92/300
8s - loss: 1.7381 - acc: 0.7686 - val_loss: 1.8656 - val_acc: 0.7586
Epoch 93/300
8s - loss: 1.7436 - acc: 0.7651 - val_loss: 1.8474 - val_acc: 0.7591
Epoch 94/300
8s - loss: 1.7268 - acc: 0.7710 - val_loss: 1.8650 - val_acc: 0.7578
Epoch 95/300
8s - loss: 1.7163 - acc: 0.7739 - val_loss: 1.8448 - val_acc: 0.7603
Epoch 96/300
8s - loss: 1.7134 - acc: 0.7755 - val_loss: 1.8560 - val_acc: 0.7610
Epoch 97/300
8s - loss: 1.7067 - acc: 0.7768 - val_loss: 1.8399 - val_acc: 0.7637
Epoch 98/300
8s - loss: 1.7481 - acc: 0.7662 - val_loss: 1.8865 - val_acc: 0.7490
Epoch 99/300
7s - loss: 1.7448 - acc: 0.7652 - val_loss: 1.8720 - val_acc: 0.7480
Epoch 100/300
7s - loss: 1.7238 - acc: 0.7715 - val_loss: 1.8436 - val_acc: 0.7581
Epoch 101/300
7s - loss: 1.7116 - acc: 0.7769 - val_loss: 1.8452 - val_acc: 0.7623
Epoch 102/300
8s - loss: 1.7178 - acc: 0.7746 - val_loss: 1.8528 - val_acc: 0.7570
Epoch 103/300
8s - loss: 1.7094 - acc: 0.7766 - val_loss: 1.8393 - val_acc: 0.7608
Epoch 104/300
7s - loss: 1.7004 - acc: 0.7805 - val_loss: 1.8423 - val_acc: 0.7655
Epoch 105/300
7s - loss: 1.6954 - acc: 0.7818 - val_loss: 1.8697 - val_acc: 0.7571
Epoch 106/300
8s - loss: 1.7751 - acc: 0.7525 - val_loss: 1.8615 - val_acc: 0.7444
Epoch 107/300
7s - loss: 1.7631 - acc: 0.7511 - val_loss: 1.8598 - val_acc: 0.7491
Epoch 108/300
8s - loss: 1.7329 - acc: 0.7697 - val_loss: 1.8719 - val_acc: 0.7595
Epoch 109/300
7s - loss: 1.7121 - acc: 0.7748 - val_loss: 1.8463 - val_acc: 0.7619
Epoch 110/300
7s - loss: 1.7004 - acc: 0.7792 - val_loss: 1.8467 - val_acc: 0.7648
Epoch 111/300
8s - loss: 1.6956 - acc: 0.7806 - val_loss: 1.8418 - val_acc: 0.7639
Epoch 112/300
8s - loss: 1.6913 - acc: 0.7839 - val_loss: 1.8527 - val_acc: 0.7631
Epoch 113/300
7s - loss: 1.6891 - acc: 0.7834 - val_loss: 1.8335 - val_acc: 0.7671
Epoch 114/300
8s - loss: 1.6853 - acc: 0.7841 - val_loss: 1.8476 - val_acc: 0.7628
Epoch 115/300
8s - loss: 1.6871 - acc: 0.7851 - val_loss: 1.8586 - val_acc: 0.7642
Epoch 116/300
8s - loss: 1.6859 - acc: 0.7859 - val_loss: 1.8449 - val_acc: 0.7615
Epoch 117/300
8s - loss: 1.6912 - acc: 0.7833 - val_loss: 1.8634 - val_acc: 0.7525
Epoch 118/300
8s - loss: 1.7174 - acc: 0.7732 - val_loss: 1.8967 - val_acc: 0.7505
Epoch 119/300
8s - loss: 1.7313 - acc: 0.7684 - val_loss: 1.8552 - val_acc: 0.7564
Epoch 120/300
8s - loss: 1.7010 - acc: 0.7792 - val_loss: 1.8614 - val_acc: 0.7636
Epoch 121/300
8s - loss: 1.6990 - acc: 0.7823 - val_loss: 1.8623 - val_acc: 0.7642
Epoch 122/300
8s - loss: 1.6966 - acc: 0.7836 - val_loss: 1.8533 - val_acc: 0.7657
Epoch 123/300
7s - loss: 1.6863 - acc: 0.7875 - val_loss: 1.8426 - val_acc: 0.7649
Epoch 124/300
7s - loss: 1.6826 - acc: 0.7857 - val_loss: 1.8363 - val_acc: 0.7649
Epoch 125/300
7s - loss: 1.6765 - acc: 0.7875 - val_loss: 1.8329 - val_acc: 0.7698
Epoch 126/300
8s - loss: 1.6790 - acc: 0.7862 - val_loss: 1.8372 - val_acc: 0.7663
Epoch 127/300
7s - loss: 1.6726 - acc: 0.7893 - val_loss: 1.8517 - val_acc: 0.7698
Epoch 128/300
8s - loss: 1.6705 - acc: 0.7899 - val_loss: 1.8286 - val_acc: 0.7689
Epoch 129/300
8s - loss: 1.6646 - acc: 0.7917 - val_loss: 1.8436 - val_acc: 0.7712
Epoch 130/300
8s - loss: 1.6658 - acc: 0.7918 - val_loss: 1.8449 - val_acc: 0.7705
Epoch 131/300
8s - loss: 1.7196 - acc: 0.7732 - val_loss: 1.9774 - val_acc: 0.7387
Epoch 132/300
8s - loss: 1.7744 - acc: 0.7575 - val_loss: 1.8728 - val_acc: 0.7503
Epoch 133/300
8s - loss: 1.7182 - acc: 0.7747 - val_loss: 1.8426 - val_acc: 0.7608
Epoch 134/300
7s - loss: 1.6936 - acc: 0.7833 - val_loss: 1.8661 - val_acc: 0.7634
Epoch 135/300
8s - loss: 1.6803 - acc: 0.7874 - val_loss: 1.8386 - val_acc: 0.7632
Epoch 136/300
8s - loss: 1.6782 - acc: 0.7884 - val_loss: 1.8457 - val_acc: 0.7678
Epoch 137/300
7s - loss: 1.6660 - acc: 0.7926 - val_loss: 1.8569 - val_acc: 0.7680
Epoch 138/300
7s - loss: 1.6592 - acc: 0.7938 - val_loss: 1.8577 - val_acc: 0.7692
Epoch 139/300
7s - loss: 1.6588 - acc: 0.7941 - val_loss: 1.8487 - val_acc: 0.7694
Epoch 140/300
8s - loss: 1.6608 - acc: 0.7936 - val_loss: 1.8587 - val_acc: 0.7680
Epoch 141/300
7s - loss: 1.6601 - acc: 0.7929 - val_loss: 1.8580 - val_acc: 0.7682
Epoch 142/300
7s - loss: 1.6533 - acc: 0.7946 - val_loss: 1.8579 - val_acc: 0.7696
Epoch 143/300
8s - loss: 1.6517 - acc: 0.7969 - val_loss: 1.8591 - val_acc: 0.7714
Epoch 144/300
8s - loss: 1.6540 - acc: 0.7952 - val_loss: 1.8382 - val_acc: 0.7712
Epoch 145/300
8s - loss: 1.6540 - acc: 0.7951 - val_loss: 1.8646 - val_acc: 0.7671
Epoch 146/300
7s - loss: 1.6505 - acc: 0.7963 - val_loss: 1.8525 - val_acc: 0.7714
Epoch 147/300
8s - loss: 1.6491 - acc: 0.7974 - val_loss: 1.8467 - val_acc: 0.7715
Epoch 148/300
8s - loss: 1.1861 - acc: 0.7942 - val_loss: 1.2825 - val_acc: 0.7743
Epoch 149/300
7s - loss: 1.1054 - acc: 0.7861 - val_loss: 1.2669 - val_acc: 0.7599
Epoch 150/300
7s - loss: 1.0922 - acc: 0.7796 - val_loss: 1.2369 - val_acc: 0.7698
Epoch 151/300
8s - loss: 1.0541 - acc: 0.7929 - val_loss: 1.2205 - val_acc: 0.7742
Epoch 152/300
8s - loss: 1.0257 - acc: 0.8009 - val_loss: 1.2088 - val_acc: 0.7804
Epoch 153/300
7s - loss: 1.0031 - acc: 0.8037 - val_loss: 1.2016 - val_acc: 0.7796
Epoch 154/300
7s - loss: 0.9973 - acc: 0.8061 - val_loss: 1.2203 - val_acc: 0.7796
Epoch 155/300
8s - loss: 1.0393 - acc: 0.7921 - val_loss: 1.2295 - val_acc: 0.7663
Epoch 156/300
7s - loss: 1.0094 - acc: 0.7991 - val_loss: 1.1931 - val_acc: 0.7805
Epoch 157/300
7s - loss: 0.9532 - acc: 0.8069 - val_loss: 1.0868 - val_acc: 0.7803
Epoch 158/300
8s - loss: 0.8781 - acc: 0.8066 - val_loss: 1.0612 - val_acc: 0.7831
Epoch 159/300
8s - loss: 0.8636 - acc: 0.8094 - val_loss: 1.0609 - val_acc: 0.7838
Epoch 160/300
7s - loss: 0.8564 - acc: 0.8109 - val_loss: 1.0396 - val_acc: 0.7860
Epoch 161/300
8s - loss: 0.8565 - acc: 0.8107 - val_loss: 1.0743 - val_acc: 0.7761
Epoch 162/300
7s - loss: 0.8827 - acc: 0.8024 - val_loss: 1.0560 - val_acc: 0.7823
Epoch 163/300
8s - loss: 0.9085 - acc: 0.7957 - val_loss: 1.1272 - val_acc: 0.7578
Epoch 164/300
8s - loss: 1.0406 - acc: 0.7513 - val_loss: 1.1091 - val_acc: 0.7527
Epoch 165/300
8s - loss: 0.9732 - acc: 0.7715 - val_loss: 1.0905 - val_acc: 0.7663
Epoch 166/300
8s - loss: 0.9191 - acc: 0.7913 - val_loss: 1.0749 - val_acc: 0.7718
Epoch 167/300
7s - loss: 0.8907 - acc: 0.7993 - val_loss: 1.0739 - val_acc: 0.7788
Epoch 168/300
7s - loss: 0.8878 - acc: 0.8001 - val_loss: 1.0678 - val_acc: 0.7787
Epoch 169/300
7s - loss: 0.8781 - acc: 0.8038 - val_loss: 1.0594 - val_acc: 0.7808
Epoch 170/300
8s - loss: 0.8622 - acc: 0.8091 - val_loss: 1.0653 - val_acc: 0.7858
Epoch 171/300
8s - loss: 0.8563 - acc: 0.8111 - val_loss: 1.0481 - val_acc: 0.7870
Epoch 172/300
8s - loss: 0.8533 - acc: 0.8116 - val_loss: 1.0415 - val_acc: 0.7874
Epoch 173/300
8s - loss: 0.8453 - acc: 0.8132 - val_loss: 1.0527 - val_acc: 0.7873
Epoch 174/300
8s - loss: 0.8444 - acc: 0.8147 - val_loss: 1.0359 - val_acc: 0.7852
Epoch 175/300
8s - loss: 0.8397 - acc: 0.8158 - val_loss: 1.0413 - val_acc: 0.7869
Epoch 176/300
8s - loss: 0.8373 - acc: 0.8172 - val_loss: 1.0392 - val_acc: 0.7868
Epoch 177/300
8s - loss: 0.8354 - acc: 0.8168 - val_loss: 1.0381 - val_acc: 0.7868
Epoch 178/300
8s - loss: 0.8377 - acc: 0.8176 - val_loss: 1.0478 - val_acc: 0.7845
Epoch 179/300
8s - loss: 0.8415 - acc: 0.8140 - val_loss: 1.0482 - val_acc: 0.7864
Epoch 180/300
7s - loss: 0.8325 - acc: 0.8161 - val_loss: 1.0396 - val_acc: 0.7887
Epoch 181/300
8s - loss: 0.8281 - acc: 0.8185 - val_loss: 1.0502 - val_acc: 0.7869
Epoch 182/300
8s - loss: 0.8230 - acc: 0.8199 - val_loss: 1.0448 - val_acc: 0.7888
Epoch 183/300
8s - loss: 0.8233 - acc: 0.8204 - val_loss: 1.0454 - val_acc: 0.7885
Epoch 184/300
7s - loss: 0.9122 - acc: 0.7927 - val_loss: 1.0978 - val_acc: 0.7661
Epoch 185/300
7s - loss: 0.9144 - acc: 0.7901 - val_loss: 1.0957 - val_acc: 0.7714
Epoch 186/300
8s - loss: 0.8743 - acc: 0.8035 - val_loss: 1.0591 - val_acc: 0.7806
Epoch 187/300
8s - loss: 0.8449 - acc: 0.8123 - val_loss: 1.0416 - val_acc: 0.7849
Epoch 188/300
8s - loss: 0.8382 - acc: 0.8148 - val_loss: 1.0413 - val_acc: 0.7859
Epoch 189/300
7s - loss: 0.8377 - acc: 0.8140 - val_loss: 1.0510 - val_acc: 0.7819
Epoch 190/300
8s - loss: 0.8397 - acc: 0.8145 - val_loss: 1.1429 - val_acc: 0.7457
Epoch 191/300
8s - loss: 1.2501 - acc: 0.6772 - val_loss: 1.2473 - val_acc: 0.6958
Epoch 192/300
7s - loss: 1.1107 - acc: 0.7192 - val_loss: 1.1278 - val_acc: 0.7398
Epoch 193/300
8s - loss: 0.9884 - acc: 0.7593 - val_loss: 1.0945 - val_acc: 0.7563
Epoch 194/300
8s - loss: 0.9176 - acc: 0.7858 - val_loss: 1.0618 - val_acc: 0.7687
Epoch 195/300
8s - loss: 0.8850 - acc: 0.7971 - val_loss: 1.0612 - val_acc: 0.7782
Epoch 196/300
8s - loss: 0.8548 - acc: 0.8077 - val_loss: 1.0778 - val_acc: 0.7819
Epoch 197/300
7s - loss: 0.8432 - acc: 0.8126 - val_loss: 1.0430 - val_acc: 0.7852
Epoch 198/300
7s - loss: 0.8378 - acc: 0.8146 - val_loss: 1.0434 - val_acc: 0.7841
Epoch 199/300
8s - loss: 0.8297 - acc: 0.8153 - val_loss: 1.0396 - val_acc: 0.7857
Epoch 200/300
8s - loss: 0.8251 - acc: 0.8180 - val_loss: 1.0219 - val_acc: 0.7878
Epoch 201/300
8s - loss: 0.8463 - acc: 0.8122 - val_loss: 1.1449 - val_acc: 0.7786
Epoch 202/300
8s - loss: 0.8654 - acc: 0.8054 - val_loss: 1.0659 - val_acc: 0.7827
Epoch 203/300
7s - loss: 0.8424 - acc: 0.8139 - val_loss: 1.0559 - val_acc: 0.7860
Epoch 204/300
8s - loss: 0.8303 - acc: 0.8168 - val_loss: 1.0589 - val_acc: 0.7887
Epoch 205/300
8s - loss: 0.8196 - acc: 0.8201 - val_loss: 1.0548 - val_acc: 0.7893
Epoch 206/300
7s - loss: 0.8325 - acc: 0.8169 - val_loss: 1.0666 - val_acc: 0.7836
Epoch 207/300
8s - loss: 0.8391 - acc: 0.8137 - val_loss: 1.0642 - val_acc: 0.7842
Epoch 208/300
8s - loss: 0.8280 - acc: 0.8168 - val_loss: 1.0421 - val_acc: 0.7875
Epoch 209/300
7s - loss: 0.8186 - acc: 0.8195 - val_loss: 1.0342 - val_acc: 0.7872
Epoch 210/300
8s - loss: 0.8203 - acc: 0.8191 - val_loss: 1.0611 - val_acc: 0.7902
Epoch 211/300
7s - loss: 0.8142 - acc: 0.8213 - val_loss: 1.0376 - val_acc: 0.7898
Epoch 212/300
8s - loss: 0.8114 - acc: 0.8196 - val_loss: 1.0465 - val_acc: 0.7907
Epoch 213/300
8s - loss: 0.8099 - acc: 0.8220 - val_loss: 1.0656 - val_acc: 0.7897
Epoch 214/300
8s - loss: 0.8102 - acc: 0.8231 - val_loss: 1.0512 - val_acc: 0.7903
Epoch 215/300
8s - loss: 0.8065 - acc: 0.8236 - val_loss: 1.0290 - val_acc: 0.7913
Epoch 216/300
8s - loss: 0.8050 - acc: 0.8242 - val_loss: 1.0333 - val_acc: 0.7906
Epoch 217/300
7s - loss: 0.8001 - acc: 0.8247 - val_loss: 1.0455 - val_acc: 0.7907
Epoch 218/300
7s - loss: 0.8021 - acc: 0.8249 - val_loss: 1.0241 - val_acc: 0.7902
Epoch 219/300
8s - loss: 0.8091 - acc: 0.8225 - val_loss: 1.0629 - val_acc: 0.7899
Epoch 220/300
8s - loss: 0.8018 - acc: 0.8249 - val_loss: 1.0291 - val_acc: 0.7905
Epoch 221/300
7s - loss: 0.8033 - acc: 0.8238 - val_loss: 1.0296 - val_acc: 0.7881
Epoch 222/300
7s - loss: 0.8032 - acc: 0.8237 - val_loss: 1.0609 - val_acc: 0.7889
Epoch 223/300
8s - loss: 0.7987 - acc: 0.8250 - val_loss: 1.0221 - val_acc: 0.7876
Epoch 224/300
8s - loss: 0.7951 - acc: 0.8261 - val_loss: 1.0313 - val_acc: 0.7913
Epoch 225/300
7s - loss: 0.7946 - acc: 0.8260 - val_loss: 1.0363 - val_acc: 0.7894
Epoch 226/300
8s - loss: 0.7939 - acc: 0.8262 - val_loss: 1.0441 - val_acc: 0.7899
Epoch 227/300
8s - loss: 0.7956 - acc: 0.8266 - val_loss: 1.0287 - val_acc: 0.7885
Epoch 228/300
8s - loss: 0.7960 - acc: 0.8251 - val_loss: 1.0259 - val_acc: 0.7901
Epoch 229/300
8s - loss: 0.7906 - acc: 0.8279 - val_loss: 1.0353 - val_acc: 0.7900
Epoch 230/300
8s - loss: 0.7886 - acc: 0.8284 - val_loss: 1.0339 - val_acc: 0.7919
Epoch 231/300
8s - loss: 0.7892 - acc: 0.8283 - val_loss: 1.0358 - val_acc: 0.7912
Epoch 232/300
8s - loss: 0.7843 - acc: 0.8284 - val_loss: 1.0359 - val_acc: 0.7894
Epoch 233/300
7s - loss: 0.7825 - acc: 0.8290 - val_loss: 1.0433 - val_acc: 0.7906
Epoch 234/300
8s - loss: 0.7932 - acc: 0.8265 - val_loss: 1.1244 - val_acc: 0.7571
Epoch 235/300
7s - loss: 0.8866 - acc: 0.7942 - val_loss: 1.0865 - val_acc: 0.7706
Epoch 236/300
8s - loss: 0.8579 - acc: 0.8058 - val_loss: 1.0388 - val_acc: 0.7782
Epoch 237/300
7s - loss: 0.8386 - acc: 0.8118 - val_loss: 1.0609 - val_acc: 0.7797
Epoch 238/300
8s - loss: 0.8112 - acc: 0.8212 - val_loss: 1.0605 - val_acc: 0.7828
Epoch 239/300
7s - loss: 0.8045 - acc: 0.8234 - val_loss: 1.0399 - val_acc: 0.7814
Epoch 240/300
8s - loss: 0.8037 - acc: 0.8244 - val_loss: 1.0463 - val_acc: 0.7890
Epoch 241/300
7s - loss: 0.7937 - acc: 0.8263 - val_loss: 1.0376 - val_acc: 0.7888
Epoch 242/300
8s - loss: 0.7890 - acc: 0.8277 - val_loss: 1.0360 - val_acc: 0.7900
Epoch 243/300
8s - loss: 0.7862 - acc: 0.8278 - val_loss: 1.0324 - val_acc: 0.7912
Epoch 244/300
7s - loss: 0.7837 - acc: 0.8288 - val_loss: 1.0379 - val_acc: 0.7895
Epoch 245/300
7s - loss: 0.7827 - acc: 0.8295 - val_loss: 1.0552 - val_acc: 0.7912
Epoch 246/300
8s - loss: 0.7843 - acc: 0.8286 - val_loss: 1.0316 - val_acc: 0.7887
Epoch 247/300
8s - loss: 0.7870 - acc: 0.8283 - val_loss: 1.0443 - val_acc: 0.7910
Epoch 248/300
8s - loss: 0.7813 - acc: 0.8296 - val_loss: 1.0331 - val_acc: 0.7903
Epoch 249/300
8s - loss: 0.7790 - acc: 0.8303 - val_loss: 1.0365 - val_acc: 0.7918
Epoch 250/300
8s - loss: 0.7785 - acc: 0.8300 - val_loss: 1.0338 - val_acc: 0.7883
Epoch 251/300
8s - loss: 0.7922 - acc: 0.8269 - val_loss: 1.0358 - val_acc: 0.7868
Epoch 252/300
7s - loss: 0.7948 - acc: 0.8257 - val_loss: 1.0563 - val_acc: 0.7901
Epoch 253/300
8s - loss: 0.7831 - acc: 0.8295 - val_loss: 1.0307 - val_acc: 0.7902
Epoch 254/300
8s - loss: 0.7790 - acc: 0.8299 - val_loss: 1.0355 - val_acc: 0.7907
Epoch 255/300
8s - loss: 0.7788 - acc: 0.8299 - val_loss: 1.0406 - val_acc: 0.7887
Epoch 256/300
8s - loss: 0.7791 - acc: 0.8294 - val_loss: 1.0473 - val_acc: 0.7916
Epoch 257/300
7s - loss: 0.7769 - acc: 0.8300 - val_loss: 1.0585 - val_acc: 0.7900
Epoch 258/300
8s - loss: 0.7819 - acc: 0.8292 - val_loss: 1.0419 - val_acc: 0.7902
Epoch 259/300
8s - loss: 0.7773 - acc: 0.8304 - val_loss: 1.0476 - val_acc: 0.7916
Epoch 260/300
7s - loss: 0.7758 - acc: 0.8306 - val_loss: 1.0377 - val_acc: 0.7919
Epoch 261/300
8s - loss: 0.7736 - acc: 0.8318 - val_loss: 1.0314 - val_acc: 0.7920
Epoch 262/300
8s - loss: 0.7729 - acc: 0.8319 - val_loss: 1.0403 - val_acc: 0.7910
Epoch 263/300
8s - loss: 0.7717 - acc: 0.8321 - val_loss: 1.0167 - val_acc: 0.7925
Epoch 264/300
7s - loss: 0.7730 - acc: 0.8318 - val_loss: 1.0402 - val_acc: 0.7929
Epoch 265/300
7s - loss: 0.7717 - acc: 0.8318 - val_loss: 1.0207 - val_acc: 0.7928
Epoch 266/300
8s - loss: 0.7693 - acc: 0.8321 - val_loss: 1.0211 - val_acc: 0.7934
Epoch 267/300
7s - loss: 0.7693 - acc: 0.8321 - val_loss: 1.0211 - val_acc: 0.7899
Epoch 268/300
8s - loss: 0.7764 - acc: 0.8308 - val_loss: 1.0435 - val_acc: 0.7916
Epoch 269/300
8s - loss: 0.7755 - acc: 0.8311 - val_loss: 1.0558 - val_acc: 0.7879
Epoch 270/300
8s - loss: 0.7738 - acc: 0.8321 - val_loss: 1.0334 - val_acc: 0.7931
Epoch 271/300
8s - loss: 0.7713 - acc: 0.8328 - val_loss: 1.0378 - val_acc: 0.7913
Epoch 272/300
8s - loss: 0.7699 - acc: 0.8326 - val_loss: 1.0203 - val_acc: 0.7937
Epoch 273/300
7s - loss: 0.7701 - acc: 0.8324 - val_loss: 1.0457 - val_acc: 0.7919
Epoch 274/300
7s - loss: 0.7668 - acc: 0.8333 - val_loss: 1.0191 - val_acc: 0.7924
Epoch 275/300
8s - loss: 0.7650 - acc: 0.8335 - val_loss: 1.0379 - val_acc: 0.7927
Epoch 276/300
8s - loss: 0.7640 - acc: 0.8342 - val_loss: 1.0308 - val_acc: 0.7897
Epoch 277/300
8s - loss: 0.7624 - acc: 0.8334 - val_loss: 1.0348 - val_acc: 0.7920
Epoch 278/300
7s - loss: 0.7618 - acc: 0.8338 - val_loss: 1.0198 - val_acc: 0.7911
Epoch 279/300
8s - loss: 0.7616 - acc: 0.8343 - val_loss: 1.0839 - val_acc: 0.7787
Epoch 280/300
8s - loss: 0.8000 - acc: 0.8226 - val_loss: 1.0598 - val_acc: 0.7880
Epoch 281/300
8s - loss: 0.7867 - acc: 0.8265 - val_loss: 1.0379 - val_acc: 0.7882
Epoch 282/300
8s - loss: 0.7726 - acc: 0.8305 - val_loss: 1.0490 - val_acc: 0.7900
Epoch 283/300
8s - loss: 0.7688 - acc: 0.8330 - val_loss: 1.0248 - val_acc: 0.7898
Epoch 284/300
8s - loss: 0.7698 - acc: 0.8325 - val_loss: 1.0325 - val_acc: 0.7886
Epoch 285/300
7s - loss: 0.7704 - acc: 0.8315 - val_loss: 1.0325 - val_acc: 0.7905
Epoch 286/300
8s - loss: 0.7648 - acc: 0.8337 - val_loss: 1.0415 - val_acc: 0.7903
Epoch 287/300
7s - loss: 0.7633 - acc: 0.8340 - val_loss: 1.0358 - val_acc: 0.7914
Epoch 288/300
8s - loss: 0.7701 - acc: 0.8313 - val_loss: 1.0366 - val_acc: 0.7833
Epoch 289/300
7s - loss: 0.7816 - acc: 0.8292 - val_loss: 1.0464 - val_acc: 0.7887
Epoch 290/300
8s - loss: 0.7729 - acc: 0.8316 - val_loss: 1.0218 - val_acc: 0.7904
Epoch 291/300
8s - loss: 0.7669 - acc: 0.8336 - val_loss: 1.0461 - val_acc: 0.7905
Epoch 292/300
8s - loss: 0.7628 - acc: 0.8339 - val_loss: 1.0477 - val_acc: 0.7922
Epoch 293/300
8s - loss: 0.7588 - acc: 0.8352 - val_loss: 1.0223 - val_acc: 0.7927
Epoch 294/300
7s - loss: 0.7590 - acc: 0.8349 - val_loss: 1.0587 - val_acc: 0.7892
Epoch 295/300
7s - loss: 0.7633 - acc: 0.8348 - val_loss: 1.0264 - val_acc: 0.7941
Epoch 296/300
7s - loss: 0.7602 - acc: 0.8352 - val_loss: 1.0414 - val_acc: 0.7873
Epoch 297/300
8s - loss: 0.7684 - acc: 0.8314 - val_loss: 1.0350 - val_acc: 0.7924
Epoch 298/300
8s - loss: 0.7618 - acc: 0.8344 - val_loss: 1.0610 - val_acc: 0.7908
Epoch 299/300
8s - loss: 0.7599 - acc: 0.8352 - val_loss: 1.0317 - val_acc: 0.7915
Epoch 300/300
8s - loss: 0.7567 - acc: 0.8358 - val_loss: 1.0356 - val_acc: 0.7905
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, None, None, 3)     0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, None, None, 64)    1792      
_________________________________________________________________
block1_conv2 (Conv2D)        (None, None, None, 64)    36928     
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, None, None, 64)    0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, None, None, 128)   73856     
_________________________________________________________________
block2_conv2 (Conv2D)        (None, None, None, 128)   147584    
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, None, None, 128)   0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, None, None, 256)   295168    
_________________________________________________________________
block3_conv2 (Conv2D)        (None, None, None, 256)   590080    
_________________________________________________________________
block3_conv3 (Conv2D)        (None, None, None, 256)   590080    
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, None, None, 256)   0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   
_________________________________________________________________
block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   
_________________________________________________________________
block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, None, None, 512)   0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   
_________________________________________________________________
block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   
_________________________________________________________________
block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, None, None, 512)   0         
_________________________________________________________________
fc1 (Conv2D)                 (None, None, None, 4096)  102764544 
_________________________________________________________________
dropout_1 (Dropout)          (None, None, None, 4096)  0         
_________________________________________________________________
fc2 (Conv2D)                 (None, None, None, 4096)  16781312  
_________________________________________________________________
dropout_2 (Dropout)          (None, None, None, 4096)  0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, None, None, 12)    49164     
_________________________________________________________________
bilinear_up_sampling2d_1 (Bi (None, None, None, 12)    0         
=================================================================
Total params: 134,309,708
Trainable params: 134,309,708
Non-trainable params: 0
_________________________________________________________________
(311, 224, 224, 3) (311, 224, 224, 12)
(56, 224, 224, 3) (56, 224, 224, 12)
(56, 224, 224) (56, 224, 224)
class 00: #TP=441608, #FP= 67867, #FN=27072, IoU=0.823
class 01: #TP=568282, #FP=120331, #FN=63378, IoU=0.756
class 02: #TP=     0, #FP=     0, #FN=30769, IoU=0.000
class 03: #TP=890412, #FP= 80235, #FN=43344, IoU=0.878
class 04: #TP= 60801, #FP= 30635, #FN=57622, IoU=0.408
class 05: #TP=239110, #FP= 85516, #FN=45223, IoU=0.647
class 06: #TP=  4862, #FP=  1674, #FN=28268, IoU=0.140
class 07: #TP=     0, #FP=     0, #FN=26520, IoU=0.000
class 08: #TP=102236, #FP= 43583, #FN=36771, IoU=0.560
class 09: #TP=   304, #FP=   425, #FN=22199, IoU=0.013
class 10: #TP=     0, #FP=     0, #FN=15713, IoU=0.000
class 11: #TP= 50107, #FP= 21868, #FN=55255, IoU=0.394
_________________
Mean IoU: 0.385
