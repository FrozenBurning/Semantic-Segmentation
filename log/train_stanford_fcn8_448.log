Train on 367 samples, validate on 101 samples
Epoch 1/150
 - 68s - loss: 3.6708 - acc: 0.2952 - val_loss: 1.9115 - val_acc: 0.4558

Epoch 00001: val_acc improved from -inf to 0.45579, saving model to stanford_fcn8_448_weights.best.hdf5
Epoch 2/150
 - 55s - loss: 1.3098 - acc: 0.6388 - val_loss: 1.2064 - val_acc: 0.5999

Epoch 00002: val_acc improved from 0.45579 to 0.59990, saving model to stanford_fcn8_448_weights.best.hdf5
Epoch 3/150
 - 52s - loss: 1.0494 - acc: 0.6936 - val_loss: 1.1231 - val_acc: 0.6285

Epoch 00003: val_acc improved from 0.59990 to 0.62852, saving model to stanford_fcn8_448_weights.best.hdf5
Epoch 4/150
 - 53s - loss: 0.9548 - acc: 0.7153 - val_loss: 1.0845 - val_acc: 0.6358

Epoch 00004: val_acc improved from 0.62852 to 0.63584, saving model to stanford_fcn8_448_weights.best.hdf5
Epoch 5/150
 - 52s - loss: 0.8855 - acc: 0.7392 - val_loss: 0.9032 - val_acc: 0.7565

Epoch 00005: val_acc improved from 0.63584 to 0.75650, saving model to stanford_fcn8_448_weights.best.hdf5
Epoch 6/150
 - 52s - loss: 0.7804 - acc: 0.7974 - val_loss: 0.7788 - val_acc: 0.8263

Epoch 00006: val_acc improved from 0.75650 to 0.82630, saving model to stanford_fcn8_448_weights.best.hdf5
Epoch 7/150
 - 52s - loss: 0.6912 - acc: 0.8261 - val_loss: 0.6589 - val_acc: 0.8394

Epoch 00007: val_acc improved from 0.82630 to 0.83941, saving model to stanford_fcn8_448_weights.best.hdf5
Epoch 8/150
 - 52s - loss: 0.6317 - acc: 0.8420 - val_loss: 0.6954 - val_acc: 0.8195

Epoch 00008: val_acc did not improve from 0.83941
Epoch 9/150
 - 55s - loss: 0.6110 - acc: 0.8465 - val_loss: 0.5924 - val_acc: 0.8554

Epoch 00009: val_acc improved from 0.83941 to 0.85538, saving model to stanford_fcn8_448_weights.best.hdf5
Epoch 10/150
 - 55s - loss: 0.5618 - acc: 0.8582 - val_loss: 0.5680 - val_acc: 0.8541

Epoch 00010: val_acc did not improve from 0.85538
Epoch 11/150
 - 55s - loss: 0.5525 - acc: 0.8623 - val_loss: 0.5283 - val_acc: 0.8626

Epoch 00011: val_acc improved from 0.85538 to 0.86259, saving model to stanford_fcn8_448_weights.best.hdf5
Epoch 12/150
 - 52s - loss: 0.5171 - acc: 0.8695 - val_loss: 0.5094 - val_acc: 0.8690

Epoch 00012: val_acc improved from 0.86259 to 0.86903, saving model to stanford_fcn8_448_weights.best.hdf5
Epoch 13/150
 - 52s - loss: 0.4926 - acc: 0.8764 - val_loss: 0.5646 - val_acc: 0.8469

Epoch 00013: val_acc did not improve from 0.86903
Epoch 14/150
 - 55s - loss: 0.4868 - acc: 0.8770 - val_loss: 0.6307 - val_acc: 0.8388

Epoch 00014: val_acc did not improve from 0.86903
Epoch 15/150
 - 55s - loss: 0.4562 - acc: 0.8859 - val_loss: 0.4598 - val_acc: 0.8802

Epoch 00015: val_acc improved from 0.86903 to 0.88020, saving model to stanford_fcn8_448_weights.best.hdf5
Epoch 16/150
 - 52s - loss: 0.4574 - acc: 0.8845 - val_loss: 0.4445 - val_acc: 0.8862

Epoch 00016: val_acc improved from 0.88020 to 0.88621, saving model to stanford_fcn8_448_weights.best.hdf5
Epoch 17/150
 - 52s - loss: 0.4252 - acc: 0.8933 - val_loss: 0.4258 - val_acc: 0.8878

Epoch 00017: val_acc improved from 0.88621 to 0.88783, saving model to stanford_fcn8_448_weights.best.hdf5
Epoch 18/150
 - 52s - loss: 0.4189 - acc: 0.8942 - val_loss: 0.4762 - val_acc: 0.8761

Epoch 00018: val_acc did not improve from 0.88783
Epoch 19/150
 - 52s - loss: 0.4075 - acc: 0.8975 - val_loss: 0.4105 - val_acc: 0.8927

Epoch 00019: val_acc improved from 0.88783 to 0.89270, saving model to stanford_fcn8_448_weights.best.hdf5
Epoch 20/150
 - 52s - loss: 0.3855 - acc: 0.9030 - val_loss: 0.4539 - val_acc: 0.8814

Epoch 00020: val_acc did not improve from 0.89270
Epoch 21/150
 - 54s - loss: 0.3817 - acc: 0.9043 - val_loss: 0.4359 - val_acc: 0.8897

Epoch 00021: val_acc did not improve from 0.89270
Epoch 22/150
 - 55s - loss: 0.3732 - acc: 0.9062 - val_loss: 0.4699 - val_acc: 0.8810

Epoch 00022: val_acc did not improve from 0.89270
Epoch 23/150
 - 55s - loss: 0.3858 - acc: 0.9029 - val_loss: 0.4487 - val_acc: 0.8832

Epoch 00023: val_acc did not improve from 0.89270
Epoch 24/150
 - 55s - loss: 0.3765 - acc: 0.9057 - val_loss: 0.3945 - val_acc: 0.8993

Epoch 00024: val_acc improved from 0.89270 to 0.89931, saving model to stanford_fcn8_448_weights.best.hdf5
Epoch 25/150
 - 52s - loss: 0.3459 - acc: 0.9134 - val_loss: 0.4612 - val_acc: 0.8814

Epoch 00025: val_acc did not improve from 0.89931
Epoch 26/150
 - 55s - loss: 0.3579 - acc: 0.9101 - val_loss: 0.4162 - val_acc: 0.8933

Epoch 00026: val_acc did not improve from 0.89931
Epoch 27/150
 - 55s - loss: 0.3444 - acc: 0.9144 - val_loss: 0.3960 - val_acc: 0.9010

Epoch 00027: val_acc improved from 0.89931 to 0.90096, saving model to stanford_fcn8_448_weights.best.hdf5
Epoch 28/150
 - 55s - loss: 0.3378 - acc: 0.9152 - val_loss: 0.3924 - val_acc: 0.9028

Epoch 00028: val_acc improved from 0.90096 to 0.90282, saving model to stanford_fcn8_448_weights.best.hdf5
Epoch 29/150
 - 52s - loss: 0.3245 - acc: 0.9190 - val_loss: 0.3922 - val_acc: 0.9036

Epoch 00029: val_acc improved from 0.90282 to 0.90361, saving model to stanford_fcn8_448_weights.best.hdf5
Epoch 30/150
 - 52s - loss: 0.3157 - acc: 0.9211 - val_loss: 0.4392 - val_acc: 0.8891

Epoch 00030: val_acc did not improve from 0.90361
Epoch 31/150
 - 52s - loss: 0.3226 - acc: 0.9193 - val_loss: 0.3835 - val_acc: 0.9031

Epoch 00031: val_acc did not improve from 0.90361
Epoch 32/150
 - 52s - loss: 0.3180 - acc: 0.9211 - val_loss: 0.4258 - val_acc: 0.8944

Epoch 00032: val_acc did not improve from 0.90361
Epoch 33/150
 - 52s - loss: 0.3246 - acc: 0.9191 - val_loss: 0.4115 - val_acc: 0.8964

Epoch 00033: val_acc did not improve from 0.90361
Epoch 34/150
 - 55s - loss: 0.3065 - acc: 0.9240 - val_loss: 0.5213 - val_acc: 0.8692

Epoch 00034: val_acc did not improve from 0.90361
Epoch 35/150
 - 55s - loss: 0.3019 - acc: 0.9252 - val_loss: 0.3830 - val_acc: 0.9071

Epoch 00035: val_acc improved from 0.90361 to 0.90714, saving model to stanford_fcn8_448_weights.best.hdf5
Epoch 36/150
 - 55s - loss: 0.2989 - acc: 0.9258 - val_loss: 0.4027 - val_acc: 0.9043

Epoch 00036: val_acc did not improve from 0.90714
Epoch 37/150
 - 55s - loss: 0.2920 - acc: 0.9275 - val_loss: 0.4051 - val_acc: 0.9021

Epoch 00037: val_acc did not improve from 0.90714
Epoch 38/150
 - 55s - loss: 0.2851 - acc: 0.9293 - val_loss: 0.3871 - val_acc: 0.9028

Epoch 00038: val_acc did not improve from 0.90714
Epoch 39/150
 - 55s - loss: 0.2791 - acc: 0.9307 - val_loss: 0.3841 - val_acc: 0.9064

Epoch 00039: val_acc did not improve from 0.90714
Epoch 40/150
 - 55s - loss: 0.3121 - acc: 0.9222 - val_loss: 0.3913 - val_acc: 0.9011

Epoch 00040: val_acc did not improve from 0.90714
Epoch 41/150
 - 55s - loss: 0.3337 - acc: 0.9162 - val_loss: 0.4680 - val_acc: 0.8895

Epoch 00041: val_acc did not improve from 0.90714
Epoch 42/150
 - 55s - loss: 0.3555 - acc: 0.9128 - val_loss: 0.4224 - val_acc: 0.9021

Epoch 00042: val_acc did not improve from 0.90714
Epoch 43/150
 - 55s - loss: 0.2924 - acc: 0.9294 - val_loss: 0.4078 - val_acc: 0.9009

Epoch 00043: val_acc did not improve from 0.90714
Epoch 44/150
 - 55s - loss: 0.2720 - acc: 0.9335 - val_loss: 0.3727 - val_acc: 0.9086

Epoch 00044: val_acc improved from 0.90714 to 0.90860, saving model to stanford_fcn8_448_weights.best.hdf5
Epoch 45/150
 - 52s - loss: 0.2640 - acc: 0.9351 - val_loss: 0.3803 - val_acc: 0.9066

Epoch 00045: val_acc did not improve from 0.90860
Epoch 46/150
 - 55s - loss: 0.2607 - acc: 0.9355 - val_loss: 0.3938 - val_acc: 0.9053

Epoch 00046: val_acc did not improve from 0.90860
Epoch 47/150
 - 55s - loss: 0.2591 - acc: 0.9357 - val_loss: 0.3779 - val_acc: 0.9072

Epoch 00047: val_acc did not improve from 0.90860
Epoch 48/150
 - 55s - loss: 0.2631 - acc: 0.9347 - val_loss: 0.4125 - val_acc: 0.9034

Epoch 00048: val_acc did not improve from 0.90860
Epoch 49/150
 - 55s - loss: 0.2623 - acc: 0.9352 - val_loss: 0.4025 - val_acc: 0.9023

Epoch 00049: val_acc did not improve from 0.90860
Epoch 50/150
 - 55s - loss: 0.2558 - acc: 0.9368 - val_loss: 0.4099 - val_acc: 0.9063

Epoch 00050: val_acc did not improve from 0.90860
Epoch 51/150
 - 55s - loss: 0.2544 - acc: 0.9370 - val_loss: 0.4004 - val_acc: 0.9075

Epoch 00051: val_acc did not improve from 0.90860
Epoch 52/150
 - 55s - loss: 0.2463 - acc: 0.9388 - val_loss: 0.4198 - val_acc: 0.8986

Epoch 00052: val_acc did not improve from 0.90860
Epoch 53/150
 - 55s - loss: 0.2485 - acc: 0.9382 - val_loss: 0.4152 - val_acc: 0.9039

Epoch 00053: val_acc did not improve from 0.90860
Epoch 54/150
 - 55s - loss: 0.2492 - acc: 0.9381 - val_loss: 0.3883 - val_acc: 0.9082

Epoch 00054: val_acc did not improve from 0.90860
Epoch 55/150
 - 55s - loss: 0.2344 - acc: 0.9422 - val_loss: 0.3911 - val_acc: 0.9080

Epoch 00055: val_acc did not improve from 0.90860
Epoch 56/150
 - 55s - loss: 0.2259 - acc: 0.9443 - val_loss: 0.4011 - val_acc: 0.9080

Epoch 00056: val_acc did not improve from 0.90860
Epoch 57/150
 - 55s - loss: 0.2221 - acc: 0.9451 - val_loss: 0.4042 - val_acc: 0.9072

Epoch 00057: val_acc did not improve from 0.90860
Epoch 58/150
 - 55s - loss: 0.2195 - acc: 0.9457 - val_loss: 0.4013 - val_acc: 0.9077

Epoch 00058: val_acc did not improve from 0.90860
Epoch 59/150
 - 55s - loss: 0.2173 - acc: 0.9462 - val_loss: 0.4100 - val_acc: 0.9067

Epoch 00059: val_acc did not improve from 0.90860
Epoch 60/150
 - 55s - loss: 0.2156 - acc: 0.9465 - val_loss: 0.4269 - val_acc: 0.9048

Epoch 00060: val_acc did not improve from 0.90860
Epoch 61/150
 - 55s - loss: 0.2139 - acc: 0.9469 - val_loss: 0.4176 - val_acc: 0.9063

Epoch 00061: val_acc did not improve from 0.90860
Epoch 62/150
 - 52s - loss: 0.2122 - acc: 0.9472 - val_loss: 0.4290 - val_acc: 0.9055

Epoch 00062: val_acc did not improve from 0.90860
Epoch 63/150
 - 52s - loss: 0.2111 - acc: 0.9474 - val_loss: 0.4413 - val_acc: 0.9041

Epoch 00063: val_acc did not improve from 0.90860
Epoch 64/150
 - 52s - loss: 0.2099 - acc: 0.9477 - val_loss: 0.4339 - val_acc: 0.9039

Epoch 00064: val_acc did not improve from 0.90860
Epoch 65/150
 - 52s - loss: 0.2065 - acc: 0.9486 - val_loss: 0.4440 - val_acc: 0.9044

Epoch 00065: val_acc did not improve from 0.90860
Epoch 66/150
 - 52s - loss: 0.2045 - acc: 0.9493 - val_loss: 0.4457 - val_acc: 0.9044

Epoch 00066: val_acc did not improve from 0.90860
Epoch 67/150
 - 52s - loss: 0.2036 - acc: 0.9496 - val_loss: 0.4498 - val_acc: 0.9039

Epoch 00067: val_acc did not improve from 0.90860
Epoch 68/150
 - 52s - loss: 0.2027 - acc: 0.9498 - val_loss: 0.4569 - val_acc: 0.9034

Epoch 00068: val_acc did not improve from 0.90860
Epoch 69/150
 - 52s - loss: 0.2020 - acc: 0.9500 - val_loss: 0.4585 - val_acc: 0.9035

Epoch 00069: val_acc did not improve from 0.90860
Epoch 70/150
 - 52s - loss: 0.2013 - acc: 0.9502 - val_loss: 0.4623 - val_acc: 0.9031

Epoch 00070: val_acc did not improve from 0.90860
Epoch 71/150
 - 52s - loss: 0.2006 - acc: 0.9504 - val_loss: 0.4653 - val_acc: 0.9030

Epoch 00071: val_acc did not improve from 0.90860
Epoch 72/150
 - 52s - loss: 0.1998 - acc: 0.9506 - val_loss: 0.4717 - val_acc: 0.9025

Epoch 00072: val_acc did not improve from 0.90860
Epoch 73/150
 - 52s - loss: 0.1990 - acc: 0.9508 - val_loss: 0.4773 - val_acc: 0.9022

Epoch 00073: val_acc did not improve from 0.90860
Epoch 74/150
 - 52s - loss: 0.1981 - acc: 0.9510 - val_loss: 0.4768 - val_acc: 0.9020

Epoch 00074: val_acc did not improve from 0.90860
Epoch 75/150
 - 52s - loss: 0.1966 - acc: 0.9515 - val_loss: 0.4837 - val_acc: 0.9017

Epoch 00075: val_acc did not improve from 0.90860
Epoch 76/150
 - 52s - loss: 0.1962 - acc: 0.9516 - val_loss: 0.4847 - val_acc: 0.9016

Epoch 00076: val_acc did not improve from 0.90860
Epoch 77/150
 - 52s - loss: 0.1960 - acc: 0.9517 - val_loss: 0.4873 - val_acc: 0.9014

Epoch 00077: val_acc did not improve from 0.90860
Epoch 78/150
 - 52s - loss: 0.1957 - acc: 0.9518 - val_loss: 0.4890 - val_acc: 0.9013

Epoch 00078: val_acc did not improve from 0.90860
Epoch 79/150
 - 52s - loss: 0.1954 - acc: 0.9518 - val_loss: 0.4896 - val_acc: 0.9013

Epoch 00079: val_acc did not improve from 0.90860
Epoch 80/150
 - 52s - loss: 0.1952 - acc: 0.9519 - val_loss: 0.4915 - val_acc: 0.9011

Epoch 00080: val_acc did not improve from 0.90860
Epoch 81/150
 - 52s - loss: 0.1949 - acc: 0.9520 - val_loss: 0.4923 - val_acc: 0.9011

Epoch 00081: val_acc did not improve from 0.90860
Epoch 82/150
 - 52s - loss: 0.1947 - acc: 0.9520 - val_loss: 0.4946 - val_acc: 0.9010

Epoch 00082: val_acc did not improve from 0.90860
Epoch 83/150
class 00: #TP=1796367, #FP=113311, #FN=27513, IoU=0.927
class 01: #TP=4699396, #FP=274764, #FN=516532, IoU=0.856
class 02: #TP= 10103, #FP= 37408, #FN=133988, IoU=0.056
class 03: #TP=5751609, #FP=117810, #FN=151051, IoU=0.955
class 04: #TP=1653214, #FP=177229, #FN=140365, IoU=0.839
class 05: #TP=3160278, #FP=254029, #FN=143274, IoU=0.888
class 06: #TP= 97120, #FP= 55828, #FN=118340, IoU=0.358
class 07: #TP=503447, #FP=234154, #FN=122115, IoU=0.586
class 08: #TP=326290, #FP=162491, #FN=49042, IoU=0.607
class 09: #TP= 74735, #FP=133473, #FN=72751, IoU=0.266
class 10: #TP=231868, #FP= 45607, #FN=213334, IoU=0.472
class 11: #TP=113897, #FP=246676, #FN=164475, IoU=0.217
_________________
Mean IoU: 0.586
class 00: #TP=1796367, #FP=113311, #FN=27513, IoU=0.927
class 01: #TP=4699396, #FP=274764, #FN=516532, IoU=0.856
class 02: #TP= 10103, #FP= 37408, #FN=133988, IoU=0.056
class 03: #TP=5751609, #FP=117810, #FN=151051, IoU=0.955
class 04: #TP=1653214, #FP=177229, #FN=140365, IoU=0.839
class 05: #TP=3160278, #FP=254029, #FN=143274, IoU=0.888
class 06: #TP= 97120, #FP= 55828, #FN=118340, IoU=0.358
class 07: #TP=503447, #FP=234154, #FN=122115, IoU=0.586
class 08: #TP=326290, #FP=162491, #FN=49042, IoU=0.607
class 09: #TP= 74735, #FP=133473, #FN=72751, IoU=0.266
class 10: #TP=231868, #FP= 45607, #FN=213334, IoU=0.472
class 11: #TP=113897, #FP=246676, #FN=164475, IoU=0.217
_________________
Mean IoU: 0.586
class 00: #TP=1796367, #FP=113311, #FN=27513, IoU=0.927
class 01: #TP=4699396, #FP=274765, #FN=516532, IoU=0.856
class 02: #TP= 10103, #FP= 37408, #FN=133988, IoU=0.056
class 03: #TP=5751609, #FP=117810, #FN=151051, IoU=0.955
class 04: #TP=1653214, #FP=177229, #FN=140365, IoU=0.839
class 05: #TP=3160278, #FP=254029, #FN=143274, IoU=0.888
class 06: #TP= 97120, #FP= 55828, #FN=118340, IoU=0.358
class 07: #TP=503447, #FP=234153, #FN=122115, IoU=0.586
class 08: #TP=326289, #FP=162491, #FN=49043, IoU=0.607
class 09: #TP= 74735, #FP=133474, #FN=72751, IoU=0.266
class 10: #TP=231868, #FP= 45607, #FN=213334, IoU=0.472
class 11: #TP=113897, #FP=246676, #FN=164475, IoU=0.217
_________________
Mean IoU: 0.586
